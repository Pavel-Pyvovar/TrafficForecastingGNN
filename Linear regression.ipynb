{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "554cdb78-6492-4009-8ced-3850315bc7b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Import libraries and define globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b68a678-4b38-4597-bffa-0d37001bbae3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pyrosm tqdm # folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7334fe4c-cf68-4141-b7ec-bd11bc22ae1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import boto3\n",
    "# import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import pyrosm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9568591-cd8e-4ad7-8a19-96683bab7aec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CITY_ID = 1_000_000\n",
    "MAP_FILE = f\"{CITY_ID}-latest.osm.pbf\"\n",
    "S3 = boto3.client('s3')\n",
    "S3_BUCKET = \"some_bucket\"\n",
    "S3_SUBDIR = f\"subdir_path\"\n",
    "S3_DATA = \"data_path\"\n",
    "S3_FILENAME = \"edge_time_aggregated_4_lags.parquet\"\n",
    "N_WEEKS = 7\n",
    "N_WEEKS_TRAINING = 5\n",
    "N_WEEKS_VALIDATION = 1\n",
    "SUBGRAPH_K = 20\n",
    "CENTRAL_NODE_ID = 2389982923 # Some popular node in the city centre of Bucharest\n",
    "TRAIN_RATIO = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c1909cf-900b-40b5-9f3e-e857026fca5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "S3.download_file(S3_BUCKET, f\"{S3_SUBDIR}/unique_edges.pickle\", \"unique_edges.pickle\")\n",
    "with open(\"unique_edges.pickle\", \"rb\") as f:\n",
    "    UNIQUE_EDGES = pickle.load(f)\n",
    "len(UNIQUE_EDGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99282d87-9c82-4b9a-9812-af9cf781c47d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_adjacency_matrix():\n",
    "    adjacency_matrix = np.zeros((len(UNIQUE_EDGES), len(UNIQUE_EDGES)))\n",
    "\n",
    "    for i, edge_i in enumerate(UNIQUE_EDGES):\n",
    "        for j, edge_j in enumerate(UNIQUE_EDGES):\n",
    "            if set(edge_i).intersection(set(edge_j)):\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "\n",
    "    adjacency_matrix = adjacency_matrix.astype(np.float32)\n",
    "    edge_index = (np.array(adjacency_matrix) > 0).nonzero()\n",
    "    return adjacency_matrix, edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e781100-6ddd-480c-8b45-cc5767a4bcaa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Visualisation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4fa0054-e795-4882-9063-1b632c6e3cb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_random_edge_and_neighbours_time_series(speeds_df, ys, dataset, model, nodes):\n",
    "    edge = random.choice(UNIQUE_EDGES)\n",
    "    neighbours = [IDX_EDGE_MAP[idx] for idx in np.nonzero(ADJACENCY_MATRIX[EDGE_IDX_MAP[edge]])[0]]\n",
    "    neighbours.remove(edge)\n",
    "    for e in [edge] + neighbours:\n",
    "        plot_edge_time_series(e, speeds_df, ys, dataset, model)\n",
    "    return plot_edges(nodes, [edge] + neighbours)\n",
    "    \n",
    "\n",
    "def plot_edge_and_neighbours_time_series(edge, speeds_df, ys, dataset, model, nodes):\n",
    "    neighbours = [IDX_EDGE_MAP[idx] for idx in np.nonzero(ADJACENCY_MATRIX[EDGE_IDX_MAP[edge]])[0]]\n",
    "    neighbours.remove(edge)\n",
    "    for e in [edge] + neighbours:\n",
    "        plot_edge_time_series(e, speeds_df, ys, dataset, model)\n",
    "    return plot_edges(nodes, [edge] + neighbours)\n",
    "    \n",
    "\n",
    "def plot_edge_time_series(predictions_df, model_name):\n",
    "\n",
    "    edge = predictions_df.edge.iloc[0]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "        x=predictions_df.minute_bucket,\n",
    "        y=predictions_df.speed_kmh,\n",
    "        mode='markers',\n",
    "        name='Ground Truth'\n",
    "    ))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "        x=predictions_df.minute_bucket,\n",
    "        y=predictions_df.preds,\n",
    "        mode='markers',\n",
    "        name=model_name\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=DATASET_DATE_RANGE,\n",
    "        y=[edge_time_naive(edge, ts) for ts in DATASET_DATE_RANGE],\n",
    "        mode='markers',\n",
    "        name='Naive predictions'\n",
    "    ))\n",
    "    # fig.add_trace(go.Scatter(\n",
    "    #     x=DATASET_DATE_RANGE,\n",
    "    #     y=[rolling_edge_time_avg_naive(edge, ts) for ts in DATASET_DATE_RANGE],\n",
    "    #     mode='markers',\n",
    "    #     name='Rolling edge-time naive predictions'\n",
    "    # ))\n",
    "\n",
    "    # Update layout with checkboxes\n",
    "    fig.update_layout(\n",
    "        title=f\"Time series for edge {edge}\",\n",
    "        title_x=0.5,\n",
    "        xaxis=dict(\n",
    "            title=\"Time [15-minute bucket]\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Speed [km/h]\"\n",
    "        ),\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                buttons=list([\n",
    "                    dict(label=\"Ground Truth\",\n",
    "                        method=\"update\",\n",
    "                        args=[{\"visible\": [True, False, False]},\n",
    "                            {\"title\": \"Trace 1\"}]),\n",
    "                    dict(label=model_name,\n",
    "                        method=\"update\",\n",
    "                        args=[{\"visible\": [True, False, False]},\n",
    "                            {\"title\": \"Trace 2\"}]),\n",
    "                    dict(label=\"Naive predictions\",\n",
    "                        method=\"update\",\n",
    "                        args=[{\"visible\": [False, True, False]},\n",
    "                            {\"title\": \"Trace 4\"}]),\n",
    "                    # dict(label=\"Rolling edge-time naive predictions\",\n",
    "                    #     method=\"update\",\n",
    "                    #     args=[{\"visible\": [False, True, False]},\n",
    "                    #         {\"title\": \"Trace 5\"}]),\n",
    "                    dict(label=\"All\",\n",
    "                        method=\"update\",\n",
    "                        args=[{\"visible\": [True, True, True]},\n",
    "                            {\"title\": \"All Traces\"}])\n",
    "                ]),\n",
    "                direction=\"down\",\n",
    "                showactive=True,\n",
    "                x=0.1,\n",
    "                xanchor=\"left\",\n",
    "                y=1.1,\n",
    "                yanchor=\"top\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Update layout with legend\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_edges(nodes, edges):\n",
    "    m = folium.Map(location=[44.435608, 26.102297], zoom_start=15)\n",
    "\n",
    "    node_ids = [n for edge in edges for n in edge]\n",
    "\n",
    "    # Add edges to the map\n",
    "    for u, v in edges:\n",
    "        x0, y0 = nodes[nodes[\"id\"] == u][[\"lat\", \"lon\"]].iloc[0]\n",
    "        x1, y1 = nodes[nodes[\"id\"] == v][[\"lat\", \"lon\"]].iloc[0]\n",
    "        folium.PolyLine(locations=[(x0, y0), (x1, y1)], color='blue', weight=5, tooltip=f\"{u, v}\").add_to(m)\n",
    "\n",
    "    # Add nodes to the map\n",
    "    for node in node_ids:\n",
    "        x, y = nodes[nodes[\"id\"] == node][[\"lat\", \"lon\"]].iloc[0]\n",
    "        folium.CircleMarker(location=(x, y), radius=5, color='red', fill=True, fill_color='red').add_to(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aed00397-ffca-428c-87a2-c936ac3e6367",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca5d915d-33d2-426b-a4bb-d147a992d16a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_city_graph():\n",
    "    S3.download_file(S3_BUCKET, f\"{S3_SUBDIR}/{CITY_ID}-latest.osm.pbf\", \"bucharest.pbf\")\n",
    "\n",
    "    osm = pyrosm.OSM(\"bucharest.pbf\")\n",
    "    nodes, edges = osm.get_network(nodes=True, network_type=\"driving+service\")\n",
    "    edges[\"edge\"] = list(zip(edges.u, edges.v))\n",
    "    print(f\"Unique OSM nodes: {nodes.id.nunique()}, unique OSM edges: {edges.id.nunique()}\")\n",
    "\n",
    "    if not os.path.isfile(S3_FILENAME):\n",
    "        S3.download_file(S3_BUCKET, f\"{S3_SUBDIR}/{S3_DATA}/{S3_FILENAME}\", S3_FILENAME)\n",
    "    \n",
    "    speeds_df = pd.read_parquet(S3_FILENAME)\n",
    "\n",
    "    print(f\"Dataset time boundaries: {speeds_df.minute_bucket.min(), speeds_df.minute_bucket.max()}\")\n",
    "    print(f\"Initial dataset shape: {speeds_df.shape}\")\n",
    "\n",
    "    speeds_df.speed_kmh.hist()\n",
    "    plt.title(\"Dataset speed distribution\")\n",
    "    plt.xlabel(\"Speed [km/h]\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    speeds_df[\"edge\"] = list(zip(speeds_df.start_node, speeds_df.end_node))\n",
    "\n",
    "    speeds_df = speeds_df[speeds_df.edge.isin(UNIQUE_EDGES)]\n",
    "\n",
    "    print(f\"Dataset shape after filtering edges of interest: {speeds_df.shape}\")\n",
    "\n",
    "    speeds_df[\"day\"] = speeds_df.minute_bucket.dt.weekday\n",
    "    speeds_df[\"hour\"] = speeds_df.minute_bucket.dt.hour\n",
    "    speeds_df[\"minute\"] = speeds_df.minute_bucket.dt.minute\n",
    "    speeds_df.sort_values([\"edge\", \"minute_bucket\"], inplace=True)\n",
    "\n",
    "    return speeds_df, nodes, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b524898-ad63-4d2b-a144-64c8f27eba80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fb37e2f-3a0d-476c-8504-b04bd6a0dd7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "subgraph_speeds_df, nodes, edges = extract_city_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fae01f5c-4e19-4ca4-a779-44ecec13ba7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "subgraph_speeds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33f822f-f725-4766-84e5-887bc00821ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATASET_START_DATE = subgraph_speeds_df.minute_bucket.min()\n",
    "DATASET_END_DATE = subgraph_speeds_df.minute_bucket.max()\n",
    "DATASET_DATE_RANGE = pd.date_range(DATASET_START_DATE, DATASET_END_DATE, freq=\"15min\")\n",
    "DATASET_RANGE_DF = pd.DataFrame(DATASET_DATE_RANGE, columns=[\"minute_bucket\"]).reset_index().set_index(\"minute_bucket\")\n",
    "\n",
    "EDGE_IDX_MAP = {edge: i for i, edge in enumerate(UNIQUE_EDGES)}\n",
    "IDX_EDGE_MAP = {i: edge for i, edge in enumerate(UNIQUE_EDGES)}\n",
    "\n",
    "SPEED_FEATURES = [col_name for col_name in subgraph_speeds_df.columns if \"lag\" in col_name]\n",
    "\n",
    "train_subgraph_speeds_df = subgraph_speeds_df[subgraph_speeds_df.minute_bucket < DATASET_START_DATE + pd.Timedelta(N_WEEKS_TRAINING, 'W')]\n",
    "MEAN_SPEED = train_subgraph_speeds_df.speed_kmh.mean()\n",
    "EDGE_AVG_DICT = train_subgraph_speeds_df[[\"speed_kmh\", \"edge\"]].groupby(\"edge\").mean().astype(int).to_dict()[\"speed_kmh\"]\n",
    "EDGE_15_MIN_BUCKET_DICT = train_subgraph_speeds_df.groupby([\"edge\", \"day\", \"hour\", \"minute\"])[\"speed_kmh\"].mean().to_dict()\n",
    "\n",
    "ADJACENCY_MATRIX, EDGE_INDEX = compute_adjacency_matrix()\n",
    "\n",
    "TRAIN_DATE_RANGE = pd.date_range(DATASET_START_DATE, DATASET_START_DATE + pd.Timedelta(N_WEEKS_TRAINING, 'W'), freq=\"15min\", inclusive=\"left\")\n",
    "VALID_DATE_RANGE = pd.date_range(TRAIN_DATE_RANGE[-1], TRAIN_DATE_RANGE[-1] + pd.Timedelta(N_WEEKS_VALIDATION, 'W'), freq=\"15min\", inclusive=\"right\")\n",
    "TEST_DATE_RANGE = pd.date_range(VALID_DATE_RANGE[-1], VALID_DATE_RANGE[-1] + pd.Timedelta(N_WEEKS_VALIDATION, 'W'), freq=\"15min\", inclusive=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1b3791e-e286-412c-b2a3-0297c8d84e3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Linear regression on all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfe11269-369e-45ce-aca0-7bb99ba61a6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_edge_neighbour_df(speeds_df, edge):\n",
    "    neighbours = set([IDX_EDGE_MAP[idx] for idx in np.nonzero(ADJACENCY_MATRIX[EDGE_IDX_MAP[edge]])[0]])\n",
    "    edge_neighbour_df = speeds_df[speeds_df.edge == edge][SPEED_FEATURES + [\"speed_kmh\", \"start_node\", \"end_node\", \"minute_bucket\"]].set_index(\"minute_bucket\")\n",
    "    for i, neighbour in enumerate(neighbours.difference(edge)):\n",
    "        neighbour_df = speeds_df[speeds_df.edge == neighbour][SPEED_FEATURES + [\"minute_bucket\"]].set_index(\"minute_bucket\")\n",
    "        edge_neighbour_df = edge_neighbour_df.join(neighbour_df, how=\"outer\", rsuffix=f\"_neighbour_{i}\")\n",
    "    edge_neighbour_df.dropna(subset=\"speed_kmh\", axis=0, inplace=True)\n",
    "    edge_neighbour_df.start_node = edge_neighbour_df.start_node.astype(int)\n",
    "    edge_neighbour_df.end_node = edge_neighbour_df.end_node.astype(int)\n",
    "    return edge_neighbour_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef0a143-c55f-42e3-b5d2-a79b9bca6b5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def apply_lin_reg_to_edge(speeds_df, edge):\n",
    "    edge_and_neighbour_df = extract_edge_neighbour_df(speeds_df, edge)\n",
    "    edge_and_neighbour_df = edge_and_neighbour_df.reset_index().copy()\n",
    "    edge_and_neighbour_df.loc[:, (\"weekday\")] = edge_and_neighbour_df.minute_bucket.dt.weekday\n",
    "    edge_and_neighbour_df.loc[:, (\"hour\")] = edge_and_neighbour_df.minute_bucket.dt.hour\n",
    "    edge_and_neighbour_df.loc[:, (\"minute\")] = edge_and_neighbour_df.minute_bucket.dt.minute\n",
    "\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoded = encoder.fit_transform(edge_and_neighbour_df[[\"weekday\", \"hour\", \"minute\"]])\n",
    "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([\"weekday\", \"hour\", \"minute\"]))\n",
    "    edge_and_neighbour_df = pd.concat([edge_and_neighbour_df.drop([\"weekday\", \"hour\", \"minute\"], axis=1), encoded_df], axis=1)\n",
    "\n",
    "    train_end_date = DATASET_START_DATE + pd.Timedelta(N_WEEKS_TRAINING, unit='W')\n",
    "    train_df = edge_and_neighbour_df[edge_and_neighbour_df.minute_bucket < train_end_date].copy()\n",
    "    train_df.dropna(axis=1, how=\"all\", inplace=True)\n",
    "    train_df.fillna(MEAN_SPEED, inplace=True)\n",
    "\n",
    "    if train_df.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    valid_end_date = train_end_date + pd.Timedelta(N_WEEKS_VALIDATION, unit='W')\n",
    "    valid_df = edge_and_neighbour_df.loc[(edge_and_neighbour_df.minute_bucket >= train_end_date) & (edge_and_neighbour_df.minute_bucket < valid_end_date), train_df.columns].copy()\n",
    "    if valid_df.shape[0] == 0:\n",
    "        return None\n",
    "    valid_df.fillna(MEAN_SPEED, inplace=True)\n",
    "\n",
    "    test_df = edge_and_neighbour_df.loc[edge_and_neighbour_df.minute_bucket >= valid_end_date, train_df.columns].copy()\n",
    "    if test_df.shape[0] == 0:\n",
    "        return None\n",
    "    test_df.fillna(MEAN_SPEED, inplace=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    drop_cols = [\"speed_kmh\", \"start_node\", \"end_node\"] + [col for col in train_df.columns if (col.startswith(\"weekday\") or col.startswith(\"hour\") or col.startswith(\"minute\"))]\n",
    "    X = train_df.drop(drop_cols, axis=1)\n",
    "\n",
    "    if X.shape[1] == 0:\n",
    "        return None\n",
    "\n",
    "    train_normalized = scaler.fit_transform(X)\n",
    "\n",
    "    train_normalized_df = pd.DataFrame(train_normalized, columns=X.columns)\n",
    "    train_normalized_df = pd.concat([train_normalized_df, train_df[drop_cols]], axis=1)\n",
    "\n",
    "    valid_normalized_df = pd.DataFrame(scaler.transform(valid_df.drop(drop_cols, axis=1)), columns=X.columns)\n",
    "    valid_normalized_df = pd.concat([valid_normalized_df, valid_df[drop_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    test_normalized_df = pd.DataFrame(scaler.transform(test_df.drop(drop_cols, axis=1)), columns=X.columns)\n",
    "    test_normalized_df = pd.concat([test_normalized_df, test_df[drop_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    lin_reg = Ridge()\n",
    "    non_features = [\"start_node\", \"end_node\", \"minute_bucket\", \"speed_kmh\"]\n",
    "    lin_reg.fit(train_normalized_df.drop(non_features, axis=1), train_normalized_df.speed_kmh)\n",
    "\n",
    "    for df, normalized_df in zip([train_df, valid_df, test_df], [train_normalized_df, valid_normalized_df, test_normalized_df]):\n",
    "        df[\"preds\"] = lin_reg.predict(normalized_df.drop(non_features, axis=1))\n",
    "\n",
    "    train_preds_df = train_df[non_features + [\"preds\"]].reset_index(drop=True)\n",
    "    valid_preds_df = valid_df[non_features + [\"preds\"]].reset_index(drop=True)\n",
    "    test_preds_df = test_df[non_features + [\"preds\"]].reset_index(drop=True)\n",
    "\n",
    "    return train_preds_df, valid_preds_df, test_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e895e5e-7514-480b-96fb-2d8147a823c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "skipped_edges = []\n",
    "train_dfs, valid_dfs, test_dfs = [], [], []\n",
    "for edge in tqdm(UNIQUE_EDGES):\n",
    "    dfs = apply_lin_reg_to_edge(subgraph_speeds_df, edge)\n",
    "\n",
    "    if dfs is None:\n",
    "        skipped_edges.append(edge)\n",
    "    else:\n",
    "        train_dfs.append(dfs[0])\n",
    "        valid_dfs.append(dfs[1])\n",
    "        test_dfs.append(dfs[2])\n",
    "\n",
    "train_df = pd.concat(train_dfs)\n",
    "valid_df = pd.concat(valid_dfs)\n",
    "test_df = pd.concat(test_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df12977b-686b-4c3e-88cf-ac6d7244c4e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "639e7bb0-6ef7-4ef1-ae9e-3b14be56922f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(skipped_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5328dfe-2dd1-4ea2-9643-41aafecfd036",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "skipped_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f28c35d2-ecbd-4620-8b4a-5d466e920369",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "UNIQUE_EDGES = list(set(UNIQUE_EDGES).difference(set(skipped_edges)))\n",
    "with open(\"unique_edges.pickle\", \"wb\") as f:\n",
    "    pickle.dump(UNIQUE_EDGES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a995cc26-92ab-43f0-9344-25c2e7aea088",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "S3.upload_file(\"unique_edges.pickle\", S3_BUCKET, f\"{S3_SUBDIR}/unique_edges.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abdda0ad-6366-4a84-95e7-b2fef8c6a990",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c33a7c8-1fcc-4528-8b1e-0163f00d1b0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for split, df in zip([\"train\", \"valid\", \"test\"], [train_df, valid_df, test_df]):\n",
    "    print(split, np.sqrt(mean_squared_error(df.speed_kmh, df.preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14e7ebcf-408f-4f52-8fc9-771bbdfb8c08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for split, df in zip([\"train\", \"valid\", \"test\"], [train_df, valid_df, test_df]):\n",
    "    df[\"start_node\"] = df.start_node.astype(int)\n",
    "    df[\"end_node\"] = df.end_node.astype(int)\n",
    "    df.to_parquet(f\"{split}.parquet\")\n",
    "    S3.upload_file(f\"{split}.parquet\", S3_BUCKET, f\"{S3_SUBDIR}/model_predictions/ridge_{len(UNIQUE_EDGES)}_edges_{N_WEEKS}_weeks/{split}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2155dcaa-0c42-4576-937b-866946673bf1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Regression on one edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f2c16a1-60ff-46ed-ba9f-4d1831ceaf37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mses, dfs = apply_lin_reg_to_edge(subgraph_speeds_df, (248729663, 9890593730))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c74ff43b-6213-41ff-9645-959a4e6b6ec7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71961f59-37dc-496b-b497-e075ebc31fae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37cb57dd-f1a6-48aa-affd-55c0c11b316d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_edge_time_series(pd.concat(dfs).reset_index(), \"Ridge regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "888c7edf-1d73-42fb-a07d-c5a2f60cdc28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mses, dfs = apply_lin_reg_to_edge(subgraph_speeds_df, (248729663, 9890593730))\n",
    "plot_edge_time_series(pd.concat(dfs).reset_index(), \"Ridge regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3c92a02-7788-4edb-a762-681695269672",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d995d5ae-74c5-4a21-962c-90aa0bff874d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2d14ba0-c1a7-4219-861c-9f7c3ffc69b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def apply_lin_reg_to_a_random_edge(subgraph_speeds_df, k):\n",
    "    for edge in random.sample(UNIQUE_EDGES, k=k):\n",
    "        mses, dfs = apply_lin_reg_to_edge(subgraph_speeds_df, edge)\n",
    "        print(mses)\n",
    "        df = pd.concat(dfs).reset_index()\n",
    "        df[\"edge\"] = list(zip(df.start_node, df.end_node))\n",
    "        plot_edge_time_series(df, \"Ridge regression, edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4024e71f-1bb4-4106-b48a-72acf604c579",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "apply_lin_reg_to_a_random_edge(subgraph_speeds_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f58c116-f066-42a7-895e-b983b8b02111",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Linear regression 317 edges 7 weeks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
